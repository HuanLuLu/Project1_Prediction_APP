{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import Dash\n",
    "from dash.dependencies import Output, Input, State\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893732e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = pickle.load(open(\"project1_model.sav\", 'rb'))\n",
    "\n",
    "#read data\n",
    "df = pd.read_pickle(\"project1_data.pkl\")\n",
    "\n",
    "#get the mean and std\n",
    "mean_std = loadtxt('mean_std.csv', delimiter=',')\n",
    "X_train_mean = mean_std[0]\n",
    "X_train_std = mean_std[1]\n",
    "\n",
    "#get the training and testing data\n",
    "X = df.drop(columns = ['y', 'label'])\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test  = X_test.values\n",
    "y_train = y_train.values.astype('int')\n",
    "y_test  = y_test.values.astype('int')\n",
    "\n",
    "X_train = (X_train - X_train_mean) / X_train_std\n",
    "X_test = (X_test - X_train_mean) / X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deedfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "precision  = cf_matrix[1,1] / sum(cf_matrix[:,1])\n",
    "recall     = cf_matrix[1,1] / sum(cf_matrix[1,:])\n",
    "f1_score  = 2*precision*recall / (precision + recall)\n",
    "\n",
    "l_train, l_test = len(y_train), len(y_test)\n",
    "\n",
    "df_class1 = df[df['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d7c0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean of all high-quality product features means as default value\n",
    "features_mean = df_class1[['x1','x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13']].mean(axis=0)\n",
    "features_mean = list(features_mean)\n",
    "features_mean = [round(i,2) for i in features_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99225306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Header(name, app):\n",
    "    title = html.H2(name, style={\"margin-top\": 5})\n",
    "    return dbc.Row([dbc.Col(title, md=9)])\n",
    "\n",
    "def LabeledSelect(label, **kwargs):\n",
    "    return dbc.FormGroup([dbc.Label(label), dbc.Select(**kwargs)])\n",
    "\n",
    "def FeaturesCol(index,val):\n",
    "    return dbc.Col(dbc.FormGroup([dbc.Label('Feature x{}'.format(index), size=\"md\"), \n",
    "                                  dbc.Input(id=\"input-x{}\".format(index),type=\"number\",value=val)]), width=6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for test\n",
    "f_dict={'x1': 'High-quality Product Feature X1 Distribution', \n",
    "        'x2': 'High-quality Product Feature X2 Distribution', \n",
    "        'x3': 'High-quality Product Feature X3 Distribution', \n",
    "        'x4': 'High-quality Product Feature X4 Distribution', \n",
    "        'x5': 'High-quality Product Feature X5 Distribution',\n",
    "        'x6': 'High-quality Product Feature X6 Distribution',\n",
    "        'x7': 'High-quality Product Feature X7 Distribution',\n",
    "        'x8': 'High-quality Product Feature X8 Distribution', \n",
    "        'x9': 'High-quality Product Feature X9 Distribution', \n",
    "        'x10': 'High-quality Product Feature X10 Distribution', \n",
    "        'x11': 'High-quality Product Feature X11 Distribution', \n",
    "        'x12': 'High-quality Product Feature X12 Distribution', \n",
    "        'x13': 'High-quality Product Feature X13 Distribution'}\n",
    "\n",
    "cards = [\n",
    "    dbc.Card(\n",
    "        [\n",
    "            html.H2(f\"{f1_score*100:.2f}%\", className=\"card-title\"),\n",
    "            html.P(\"Model Test F1 Score\", className=\"card-text\"),\n",
    "        ],\n",
    "        body=True,\n",
    "        color=\"light\",\n",
    "    ),\n",
    "    dbc.Card(\n",
    "        [\n",
    "            html.H2(f\"{precision*100:.2f}%\", className=\"card-title\"),\n",
    "            html.P(\"Model Test Precision\", className=\"card-text\"),\n",
    "        ],\n",
    "        body=True,\n",
    "        color=\"dark\",\n",
    "        inverse=True,\n",
    "    ),\n",
    "    dbc.Card(\n",
    "        [\n",
    "            html.H2(f\"{l_train} / {l_test}\", className=\"card-title\"),\n",
    "            html.P(\"Train / Test Split\", className=\"card-text\"),\n",
    "        ],\n",
    "        body=True,\n",
    "        color=\"primary\",\n",
    "        inverse=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "graphs = [\n",
    "    [\n",
    "        LabeledSelect(\n",
    "            id=\"selected-features\",\n",
    "            options=[{\"label\": v, \"value\": k} for k, v in f_dict.items()],\n",
    "            label=\"Features\",\n",
    "            value='x1'\n",
    "        ),\n",
    "        dcc.Graph(id='graph_feature'),\n",
    "    ],\n",
    "    [        \n",
    "        dbc.Row([FeaturesCol(1,features_mean[0]), FeaturesCol(2,features_mean[1])]), \n",
    "        dbc.Row([FeaturesCol(3,features_mean[2]), FeaturesCol(4,features_mean[3])]), \n",
    "        dbc.Row([FeaturesCol(5,features_mean[4]), FeaturesCol(6,features_mean[5])]), \n",
    "        dbc.Row([FeaturesCol(7,features_mean[6]), FeaturesCol(8,features_mean[7])]), \n",
    "        dbc.Row([FeaturesCol(9,features_mean[8]), FeaturesCol(10,features_mean[9])]), \n",
    "        dbc.Row([FeaturesCol(11,features_mean[10]), FeaturesCol(12,features_mean[11])]), \n",
    "        dbc.Row([FeaturesCol(13,features_mean[12])])\n",
    "    ],\n",
    "\n",
    "]\n",
    "\n",
    "results = [\n",
    "    [\n",
    "        dbc.Button(\"Prediction\", id=\"pred_submit\", n_clicks=0,outline=True, color=\"primary\", className=\"me-1\")\n",
    "    ],\n",
    "    [\n",
    "        html.Span(id=\"Prediction Result\", style={'font-style': 'italic', 'font-weight': 'bold'})\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Dash(external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph_feature\", \"figure\"),\n",
    "    Output(\"Prediction Result\", \"children\"),\n",
    "    Input(\"selected-features\", \"value\"),\n",
    "    Input('pred_submit', 'n_clicks'),\n",
    "    State(\"input-x1\", \"value\"),\n",
    "    State(\"input-x2\", \"value\"),\n",
    "    State(\"input-x3\", \"value\"),\n",
    "    State(\"input-x4\", \"value\"),\n",
    "    State(\"input-x5\", \"value\"),\n",
    "    State(\"input-x6\", \"value\"),\n",
    "    State(\"input-x7\", \"value\"),\n",
    "    State(\"input-x8\", \"value\"),\n",
    "    State(\"input-x9\", \"value\"),\n",
    "    State(\"input-x10\", \"value\"),\n",
    "    State(\"input-x11\", \"value\"),\n",
    "    State(\"input-x12\", \"value\"),\n",
    "    State(\"input-x13\", \"value\"),\n",
    ")\n",
    "def update_figures(sele_f, _,x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13):\n",
    "    #Fileter based on the selected features\n",
    "    fig = px.histogram(df_class1,\n",
    "                       x = sele_f,\n",
    "                       marginal=\"box\",\n",
    "                       color_discrete_sequence=['teal'])\n",
    "    input_data = [[x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13]]\n",
    "    input_data = (input_data - X_train_mean) / X_train_std\n",
    "    output_pred = model.predict(input_data)[0]\n",
    "    \n",
    "    rslt = \"Based on the input data, we will get a {} product.\".format(\"High-Quality\" if output_pred == 1 else \"Low-Quality\")\n",
    "    return fig, rslt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313498e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "app.layout = dbc.Container(\n",
    "    [\n",
    "        Header(\"Project1 Production Quality Prediction\", app),\n",
    "        html.Hr(),\n",
    "        dbc.Row([dbc.Col(card) for card in cards]),\n",
    "        html.Br(),\n",
    "        dbc.Row([dbc.Col(graph) for graph in graphs]),\n",
    "        html.Br(),\n",
    "        dbc.Row([dbc.Col(results[0], width=1.5), dbc.Col(results[1], width=9)])\n",
    "    ],\n",
    "    fluid=False,\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b3576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
